---
title: "Map Reduce Theory"
author: "Aaron Palumbo"
date: "Friday, September 11, 2015"
output: html_document
toc: true
---

Exercises: 2.5.1, 2.6.1

## Exercise 2.5.1:

What is the communication cost of each of the following algorithms, as a function of the size of the relations, matrices, or  vectors to which they are applied?

### 2.5.1 (a)

The matrix-vector multiplication algorithm of Section 2.3.2.

Our matrix-vector multiplication algorithm ($M \cdot v$) produces a key value pair for each entry in the matirx $M$. The communication cost is therefore $O(r \times c)$ where $r$ and $c$ are the number of rows and columns of $M$.


### 2.5.1 (b)

The union algorithm of Section 2.3.6.

Here, for the union of $R$ and $S$, the mapper funtion passes key value pairs for each entry in $R$ and $S$. Therefore the communication cost is the total number of entries in $R$ (*r*) plus the total number of entries in $S$ (*s*) or $O(r + s)$.


### 2.5.1 (c)

The aggregation algorithm of Section 2.3.8.

Here the communication cost of grouping relation $R(A, B, C)$ is just the number of tuples $(a, b, c)$ in the relation $R$.

\hline

## Exercise 2.6.1:

### 2.6.1 (a)

The multiplication of an $n \time n$ matrix by a vector of length $n$.


### 2.6.1 (b)

The natural join of $R(A, B)$ and $S(B, C), where $A$, $B$, and $C$ have domains of sized $a$, $b$, and $c$, respectively.



